{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "dataset_root_path = os.path.join(os.path.expanduser(\"~\"), \"Datasets\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images to [-1, 1]\n",
    "])\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=dataset_root_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=dataset_root_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.297921  [   64/60000]\n",
      "loss: 2.285061  [ 6464/60000]\n",
      "loss: 2.267697  [12864/60000]\n",
      "loss: 2.265239  [19264/60000]\n",
      "loss: 2.253643  [25664/60000]\n",
      "loss: 2.222579  [32064/60000]\n",
      "loss: 2.241020  [38464/60000]\n",
      "loss: 2.201527  [44864/60000]\n",
      "loss: 2.200845  [51264/60000]\n",
      "loss: 2.190714  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 2.169447 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.175487  [   64/60000]\n",
      "loss: 2.170328  [ 6464/60000]\n",
      "loss: 2.111295  [12864/60000]\n",
      "loss: 2.130999  [19264/60000]\n",
      "loss: 2.097296  [25664/60000]\n",
      "loss: 2.031726  [32064/60000]\n",
      "loss: 2.073481  [38464/60000]\n",
      "loss: 1.988483  [44864/60000]\n",
      "loss: 1.992541  [51264/60000]\n",
      "loss: 1.951858  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.928513 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.951113  [   64/60000]\n",
      "loss: 1.935081  [ 6464/60000]\n",
      "loss: 1.811776  [12864/60000]\n",
      "loss: 1.857598  [19264/60000]\n",
      "loss: 1.765335  [25664/60000]\n",
      "loss: 1.700122  [32064/60000]\n",
      "loss: 1.736666  [38464/60000]\n",
      "loss: 1.618999  [44864/60000]\n",
      "loss: 1.643285  [51264/60000]\n",
      "loss: 1.566424  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 1.557709 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.613369  [   64/60000]\n",
      "loss: 1.588241  [ 6464/60000]\n",
      "loss: 1.423556  [12864/60000]\n",
      "loss: 1.503872  [19264/60000]\n",
      "loss: 1.392007  [25664/60000]\n",
      "loss: 1.372615  [32064/60000]\n",
      "loss: 1.396191  [38464/60000]\n",
      "loss: 1.300965  [44864/60000]\n",
      "loss: 1.340785  [51264/60000]\n",
      "loss: 1.261698  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.269854 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.341193  [   64/60000]\n",
      "loss: 1.328895  [ 6464/60000]\n",
      "loss: 1.152321  [12864/60000]\n",
      "loss: 1.261990  [19264/60000]\n",
      "loss: 1.148902  [25664/60000]\n",
      "loss: 1.161921  [32064/60000]\n",
      "loss: 1.186429  [38464/60000]\n",
      "loss: 1.107929  [44864/60000]\n",
      "loss: 1.152116  [51264/60000]\n",
      "loss: 1.089716  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.094552 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.expanduser(\"~\"), \"Models\", \"fashion_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to /Users/anton/Models/fashion_mnist.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Saved PyTorch Model State to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(model_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.25)  # Dropout after conv layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)  # Dropout after fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.dropout1(x)  # Apply dropout after convolutional layers\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)  # Apply dropout after the first fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.156423  [   64/60000]\n",
      "loss: 0.219439  [ 6464/60000]\n",
      "loss: 0.076210  [12864/60000]\n",
      "loss: 0.283038  [19264/60000]\n",
      "loss: 0.154572  [25664/60000]\n",
      "loss: 0.297373  [32064/60000]\n",
      "loss: 0.248819  [38464/60000]\n",
      "loss: 0.265889  [44864/60000]\n",
      "loss: 0.236396  [51264/60000]\n",
      "loss: 0.274124  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.231828 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.124240  [   64/60000]\n",
      "loss: 0.225014  [ 6464/60000]\n",
      "loss: 0.079173  [12864/60000]\n",
      "loss: 0.317916  [19264/60000]\n",
      "loss: 0.134249  [25664/60000]\n",
      "loss: 0.232954  [32064/60000]\n",
      "loss: 0.137080  [38464/60000]\n",
      "loss: 0.249699  [44864/60000]\n",
      "loss: 0.159286  [51264/60000]\n",
      "loss: 0.177430  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.245669 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.122279  [   64/60000]\n",
      "loss: 0.148368  [ 6464/60000]\n",
      "loss: 0.100633  [12864/60000]\n",
      "loss: 0.228612  [19264/60000]\n",
      "loss: 0.115710  [25664/60000]\n",
      "loss: 0.341340  [32064/60000]\n",
      "loss: 0.238999  [38464/60000]\n",
      "loss: 0.177641  [44864/60000]\n",
      "loss: 0.106683  [51264/60000]\n",
      "loss: 0.177325  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.230867 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.160428  [   64/60000]\n",
      "loss: 0.162161  [ 6464/60000]\n",
      "loss: 0.091855  [12864/60000]\n",
      "loss: 0.211303  [19264/60000]\n",
      "loss: 0.267129  [25664/60000]\n",
      "loss: 0.302763  [32064/60000]\n",
      "loss: 0.142333  [38464/60000]\n",
      "loss: 0.217928  [44864/60000]\n",
      "loss: 0.180799  [51264/60000]\n",
      "loss: 0.279359  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.242144 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.185789  [   64/60000]\n",
      "loss: 0.160515  [ 6464/60000]\n",
      "loss: 0.132541  [12864/60000]\n",
      "loss: 0.189642  [19264/60000]\n",
      "loss: 0.146732  [25664/60000]\n",
      "loss: 0.330988  [32064/60000]\n",
      "loss: 0.150754  [38464/60000]\n",
      "loss: 0.175909  [44864/60000]\n",
      "loss: 0.117523  [51264/60000]\n",
      "loss: 0.142912  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.233632 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.230449  [   64/60000]\n",
      "loss: 0.114764  [ 6464/60000]\n",
      "loss: 0.061108  [12864/60000]\n",
      "loss: 0.162163  [19264/60000]\n",
      "loss: 0.111825  [25664/60000]\n",
      "loss: 0.223270  [32064/60000]\n",
      "loss: 0.223557  [38464/60000]\n",
      "loss: 0.262494  [44864/60000]\n",
      "loss: 0.187072  [51264/60000]\n",
      "loss: 0.156696  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.226548 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.167718  [   64/60000]\n",
      "loss: 0.168946  [ 6464/60000]\n",
      "loss: 0.069799  [12864/60000]\n",
      "loss: 0.179315  [19264/60000]\n",
      "loss: 0.145780  [25664/60000]\n",
      "loss: 0.278806  [32064/60000]\n",
      "loss: 0.188069  [38464/60000]\n",
      "loss: 0.312277  [44864/60000]\n",
      "loss: 0.158304  [51264/60000]\n",
      "loss: 0.202716  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.240037 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.135582  [   64/60000]\n",
      "loss: 0.175829  [ 6464/60000]\n",
      "loss: 0.109750  [12864/60000]\n",
      "loss: 0.197403  [19264/60000]\n",
      "loss: 0.214766  [25664/60000]\n",
      "loss: 0.150087  [32064/60000]\n",
      "loss: 0.108997  [38464/60000]\n",
      "loss: 0.223510  [44864/60000]\n",
      "loss: 0.184277  [51264/60000]\n",
      "loss: 0.179881  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.229169 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.144926  [   64/60000]\n",
      "loss: 0.274211  [ 6464/60000]\n",
      "loss: 0.081811  [12864/60000]\n",
      "loss: 0.139571  [19264/60000]\n",
      "loss: 0.107096  [25664/60000]\n",
      "loss: 0.290338  [32064/60000]\n",
      "loss: 0.124963  [38464/60000]\n",
      "loss: 0.200677  [44864/60000]\n",
      "loss: 0.272722  [51264/60000]\n",
      "loss: 0.123793  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.250041 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.099020  [   64/60000]\n",
      "loss: 0.147410  [ 6464/60000]\n",
      "loss: 0.038069  [12864/60000]\n",
      "loss: 0.220454  [19264/60000]\n",
      "loss: 0.118069  [25664/60000]\n",
      "loss: 0.235792  [32064/60000]\n",
      "loss: 0.204291  [38464/60000]\n",
      "loss: 0.177990  [44864/60000]\n",
      "loss: 0.147827  [51264/60000]\n",
      "loss: 0.152043  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.225719 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.185274  [   64/60000]\n",
      "loss: 0.170589  [ 6464/60000]\n",
      "loss: 0.051056  [12864/60000]\n",
      "loss: 0.115519  [19264/60000]\n",
      "loss: 0.122362  [25664/60000]\n",
      "loss: 0.194069  [32064/60000]\n",
      "loss: 0.260363  [38464/60000]\n",
      "loss: 0.176314  [44864/60000]\n",
      "loss: 0.157933  [51264/60000]\n",
      "loss: 0.105881  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.238697 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.167001  [   64/60000]\n",
      "loss: 0.107427  [ 6464/60000]\n",
      "loss: 0.092749  [12864/60000]\n",
      "loss: 0.205326  [19264/60000]\n",
      "loss: 0.124649  [25664/60000]\n",
      "loss: 0.180849  [32064/60000]\n",
      "loss: 0.162335  [38464/60000]\n",
      "loss: 0.225236  [44864/60000]\n",
      "loss: 0.082432  [51264/60000]\n",
      "loss: 0.133631  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.239493 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.093088  [   64/60000]\n",
      "loss: 0.148608  [ 6464/60000]\n",
      "loss: 0.040005  [12864/60000]\n",
      "loss: 0.129990  [19264/60000]\n",
      "loss: 0.141162  [25664/60000]\n",
      "loss: 0.479618  [32064/60000]\n",
      "loss: 0.208674  [38464/60000]\n",
      "loss: 0.244295  [44864/60000]\n",
      "loss: 0.133129  [51264/60000]\n",
      "loss: 0.290959  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.239306 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.171753  [   64/60000]\n",
      "loss: 0.099231  [ 6464/60000]\n",
      "loss: 0.069663  [12864/60000]\n",
      "loss: 0.189852  [19264/60000]\n",
      "loss: 0.128531  [25664/60000]\n",
      "loss: 0.216972  [32064/60000]\n",
      "loss: 0.205687  [38464/60000]\n",
      "loss: 0.247806  [44864/60000]\n",
      "loss: 0.148993  [51264/60000]\n",
      "loss: 0.103143  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.240892 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.108554  [   64/60000]\n",
      "loss: 0.200934  [ 6464/60000]\n",
      "loss: 0.058839  [12864/60000]\n",
      "loss: 0.182023  [19264/60000]\n",
      "loss: 0.134274  [25664/60000]\n",
      "loss: 0.232268  [32064/60000]\n",
      "loss: 0.157957  [38464/60000]\n",
      "loss: 0.141747  [44864/60000]\n",
      "loss: 0.104647  [51264/60000]\n",
      "loss: 0.270361  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.246845 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.273974  [   64/60000]\n",
      "loss: 0.170341  [ 6464/60000]\n",
      "loss: 0.049385  [12864/60000]\n",
      "loss: 0.136260  [19264/60000]\n",
      "loss: 0.082798  [25664/60000]\n",
      "loss: 0.242901  [32064/60000]\n",
      "loss: 0.141481  [38464/60000]\n",
      "loss: 0.199213  [44864/60000]\n",
      "loss: 0.148755  [51264/60000]\n",
      "loss: 0.136856  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.244957 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.129981  [   64/60000]\n",
      "loss: 0.080924  [ 6464/60000]\n",
      "loss: 0.085128  [12864/60000]\n",
      "loss: 0.129987  [19264/60000]\n",
      "loss: 0.129949  [25664/60000]\n",
      "loss: 0.266312  [32064/60000]\n",
      "loss: 0.084220  [38464/60000]\n",
      "loss: 0.232056  [44864/60000]\n",
      "loss: 0.197818  [51264/60000]\n",
      "loss: 0.122287  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.237840 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.127749  [   64/60000]\n",
      "loss: 0.078099  [ 6464/60000]\n",
      "loss: 0.063357  [12864/60000]\n",
      "loss: 0.166524  [19264/60000]\n",
      "loss: 0.122065  [25664/60000]\n",
      "loss: 0.158263  [32064/60000]\n",
      "loss: 0.127318  [38464/60000]\n",
      "loss: 0.217310  [44864/60000]\n",
      "loss: 0.107873  [51264/60000]\n",
      "loss: 0.093171  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.249510 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.084600  [   64/60000]\n",
      "loss: 0.140608  [ 6464/60000]\n",
      "loss: 0.069910  [12864/60000]\n",
      "loss: 0.142675  [19264/60000]\n",
      "loss: 0.105029  [25664/60000]\n",
      "loss: 0.154944  [32064/60000]\n",
      "loss: 0.163148  [38464/60000]\n",
      "loss: 0.164634  [44864/60000]\n",
      "loss: 0.086175  [51264/60000]\n",
      "loss: 0.110048  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.267538 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.095987  [   64/60000]\n",
      "loss: 0.164398  [ 6464/60000]\n",
      "loss: 0.030761  [12864/60000]\n",
      "loss: 0.124795  [19264/60000]\n",
      "loss: 0.113042  [25664/60000]\n",
      "loss: 0.179218  [32064/60000]\n",
      "loss: 0.146584  [38464/60000]\n",
      "loss: 0.154034  [44864/60000]\n",
      "loss: 0.108480  [51264/60000]\n",
      "loss: 0.174852  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.240792 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.178623  [   64/60000]\n",
      "loss: 0.063868  [ 6464/60000]\n",
      "loss: 0.064533  [12864/60000]\n",
      "loss: 0.120430  [19264/60000]\n",
      "loss: 0.129562  [25664/60000]\n",
      "loss: 0.168101  [32064/60000]\n",
      "loss: 0.134475  [38464/60000]\n",
      "loss: 0.130426  [44864/60000]\n",
      "loss: 0.179884  [51264/60000]\n",
      "loss: 0.122795  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.253391 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.125659  [   64/60000]\n",
      "loss: 0.088600  [ 6464/60000]\n",
      "loss: 0.078790  [12864/60000]\n",
      "loss: 0.109442  [19264/60000]\n",
      "loss: 0.118758  [25664/60000]\n",
      "loss: 0.177460  [32064/60000]\n",
      "loss: 0.119963  [38464/60000]\n",
      "loss: 0.149451  [44864/60000]\n",
      "loss: 0.145281  [51264/60000]\n",
      "loss: 0.093351  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.259902 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.113699  [   64/60000]\n",
      "loss: 0.075259  [ 6464/60000]\n",
      "loss: 0.023834  [12864/60000]\n",
      "loss: 0.165653  [19264/60000]\n",
      "loss: 0.157953  [25664/60000]\n",
      "loss: 0.159489  [32064/60000]\n",
      "loss: 0.097182  [38464/60000]\n",
      "loss: 0.116988  [44864/60000]\n",
      "loss: 0.106934  [51264/60000]\n",
      "loss: 0.087381  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.260507 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.206147  [   64/60000]\n",
      "loss: 0.172984  [ 6464/60000]\n",
      "loss: 0.071851  [12864/60000]\n",
      "loss: 0.105770  [19264/60000]\n",
      "loss: 0.167205  [25664/60000]\n",
      "loss: 0.200217  [32064/60000]\n",
      "loss: 0.060254  [38464/60000]\n",
      "loss: 0.167665  [44864/60000]\n",
      "loss: 0.107042  [51264/60000]\n",
      "loss: 0.228631  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.258251 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.160151  [   64/60000]\n",
      "loss: 0.063493  [ 6464/60000]\n",
      "loss: 0.052553  [12864/60000]\n",
      "loss: 0.268460  [19264/60000]\n",
      "loss: 0.116445  [25664/60000]\n",
      "loss: 0.170102  [32064/60000]\n",
      "loss: 0.133167  [38464/60000]\n",
      "loss: 0.137946  [44864/60000]\n",
      "loss: 0.104874  [51264/60000]\n",
      "loss: 0.099747  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.246691 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.095503  [   64/60000]\n",
      "loss: 0.075390  [ 6464/60000]\n",
      "loss: 0.038594  [12864/60000]\n",
      "loss: 0.078595  [19264/60000]\n",
      "loss: 0.141522  [25664/60000]\n",
      "loss: 0.302102  [32064/60000]\n",
      "loss: 0.116741  [38464/60000]\n",
      "loss: 0.191444  [44864/60000]\n",
      "loss: 0.055967  [51264/60000]\n",
      "loss: 0.149200  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.257958 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.105454  [   64/60000]\n",
      "loss: 0.199919  [ 6464/60000]\n",
      "loss: 0.056451  [12864/60000]\n",
      "loss: 0.124552  [19264/60000]\n",
      "loss: 0.143061  [25664/60000]\n",
      "loss: 0.219000  [32064/60000]\n",
      "loss: 0.123489  [38464/60000]\n",
      "loss: 0.243132  [44864/60000]\n",
      "loss: 0.141201  [51264/60000]\n",
      "loss: 0.205572  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.260114 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.164900  [   64/60000]\n",
      "loss: 0.165310  [ 6464/60000]\n",
      "loss: 0.086505  [12864/60000]\n",
      "loss: 0.105244  [19264/60000]\n",
      "loss: 0.129681  [25664/60000]\n",
      "loss: 0.152660  [32064/60000]\n",
      "loss: 0.092874  [38464/60000]\n",
      "loss: 0.112937  [44864/60000]\n",
      "loss: 0.196218  [51264/60000]\n",
      "loss: 0.088470  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.264922 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.075359  [   64/60000]\n",
      "loss: 0.178862  [ 6464/60000]\n",
      "loss: 0.062495  [12864/60000]\n",
      "loss: 0.120976  [19264/60000]\n",
      "loss: 0.158677  [25664/60000]\n",
      "loss: 0.175983  [32064/60000]\n",
      "loss: 0.166094  [38464/60000]\n",
      "loss: 0.140251  [44864/60000]\n",
      "loss: 0.231003  [51264/60000]\n",
      "loss: 0.117943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.258317 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.102517  [   64/60000]\n",
      "loss: 0.075026  [ 6464/60000]\n",
      "loss: 0.099312  [12864/60000]\n",
      "loss: 0.155674  [19264/60000]\n",
      "loss: 0.114330  [25664/60000]\n",
      "loss: 0.153715  [32064/60000]\n",
      "loss: 0.100893  [38464/60000]\n",
      "loss: 0.203154  [44864/60000]\n",
      "loss: 0.217742  [51264/60000]\n",
      "loss: 0.126137  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.271273 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.175392  [   64/60000]\n",
      "loss: 0.127738  [ 6464/60000]\n",
      "loss: 0.060272  [12864/60000]\n",
      "loss: 0.136710  [19264/60000]\n",
      "loss: 0.113654  [25664/60000]\n",
      "loss: 0.082525  [32064/60000]\n",
      "loss: 0.035642  [38464/60000]\n",
      "loss: 0.095409  [44864/60000]\n",
      "loss: 0.088248  [51264/60000]\n",
      "loss: 0.099020  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.271169 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.124919  [   64/60000]\n",
      "loss: 0.086672  [ 6464/60000]\n",
      "loss: 0.013456  [12864/60000]\n",
      "loss: 0.094347  [19264/60000]\n",
      "loss: 0.178808  [25664/60000]\n",
      "loss: 0.170426  [32064/60000]\n",
      "loss: 0.119223  [38464/60000]\n",
      "loss: 0.102556  [44864/60000]\n",
      "loss: 0.125902  [51264/60000]\n",
      "loss: 0.058770  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.266894 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.133375  [   64/60000]\n",
      "loss: 0.135112  [ 6464/60000]\n",
      "loss: 0.053360  [12864/60000]\n",
      "loss: 0.074894  [19264/60000]\n",
      "loss: 0.170493  [25664/60000]\n",
      "loss: 0.150061  [32064/60000]\n",
      "loss: 0.145912  [38464/60000]\n",
      "loss: 0.208782  [44864/60000]\n",
      "loss: 0.099322  [51264/60000]\n",
      "loss: 0.099347  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.265061 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.119369  [   64/60000]\n",
      "loss: 0.176173  [ 6464/60000]\n",
      "loss: 0.104705  [12864/60000]\n",
      "loss: 0.063150  [19264/60000]\n",
      "loss: 0.162885  [25664/60000]\n",
      "loss: 0.138549  [32064/60000]\n",
      "loss: 0.043999  [38464/60000]\n",
      "loss: 0.152579  [44864/60000]\n",
      "loss: 0.146368  [51264/60000]\n",
      "loss: 0.125868  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.278180 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.196601  [   64/60000]\n",
      "loss: 0.086143  [ 6464/60000]\n",
      "loss: 0.073667  [12864/60000]\n",
      "loss: 0.118380  [19264/60000]\n",
      "loss: 0.187477  [25664/60000]\n",
      "loss: 0.103286  [32064/60000]\n",
      "loss: 0.075187  [38464/60000]\n",
      "loss: 0.065618  [44864/60000]\n",
      "loss: 0.143963  [51264/60000]\n",
      "loss: 0.072034  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.272646 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.162766  [   64/60000]\n",
      "loss: 0.084945  [ 6464/60000]\n",
      "loss: 0.068581  [12864/60000]\n",
      "loss: 0.103853  [19264/60000]\n",
      "loss: 0.084373  [25664/60000]\n",
      "loss: 0.248970  [32064/60000]\n",
      "loss: 0.120079  [38464/60000]\n",
      "loss: 0.101481  [44864/60000]\n",
      "loss: 0.045464  [51264/60000]\n",
      "loss: 0.154508  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.267861 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.057983  [   64/60000]\n",
      "loss: 0.085419  [ 6464/60000]\n",
      "loss: 0.067675  [12864/60000]\n",
      "loss: 0.083113  [19264/60000]\n",
      "loss: 0.163634  [25664/60000]\n",
      "loss: 0.140440  [32064/60000]\n",
      "loss: 0.138299  [38464/60000]\n",
      "loss: 0.147939  [44864/60000]\n",
      "loss: 0.030235  [51264/60000]\n",
      "loss: 0.170002  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.261147 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.113133  [   64/60000]\n",
      "loss: 0.152293  [ 6464/60000]\n",
      "loss: 0.040979  [12864/60000]\n",
      "loss: 0.076375  [19264/60000]\n",
      "loss: 0.151121  [25664/60000]\n",
      "loss: 0.110159  [32064/60000]\n",
      "loss: 0.161207  [38464/60000]\n",
      "loss: 0.133034  [44864/60000]\n",
      "loss: 0.059956  [51264/60000]\n",
      "loss: 0.149298  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.265875 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.148792  [   64/60000]\n",
      "loss: 0.076801  [ 6464/60000]\n",
      "loss: 0.030034  [12864/60000]\n",
      "loss: 0.055438  [19264/60000]\n",
      "loss: 0.124415  [25664/60000]\n",
      "loss: 0.099428  [32064/60000]\n",
      "loss: 0.109704  [38464/60000]\n",
      "loss: 0.128885  [44864/60000]\n",
      "loss: 0.135263  [51264/60000]\n",
      "loss: 0.193667  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.279099 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.093099  [   64/60000]\n",
      "loss: 0.157427  [ 6464/60000]\n",
      "loss: 0.042004  [12864/60000]\n",
      "loss: 0.152316  [19264/60000]\n",
      "loss: 0.084785  [25664/60000]\n",
      "loss: 0.181294  [32064/60000]\n",
      "loss: 0.102392  [38464/60000]\n",
      "loss: 0.188930  [44864/60000]\n",
      "loss: 0.188684  [51264/60000]\n",
      "loss: 0.083169  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.265934 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.099315  [   64/60000]\n",
      "loss: 0.202240  [ 6464/60000]\n",
      "loss: 0.023483  [12864/60000]\n",
      "loss: 0.096866  [19264/60000]\n",
      "loss: 0.119095  [25664/60000]\n",
      "loss: 0.155373  [32064/60000]\n",
      "loss: 0.131580  [38464/60000]\n",
      "loss: 0.119001  [44864/60000]\n",
      "loss: 0.047516  [51264/60000]\n",
      "loss: 0.167313  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.250857 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.069110  [   64/60000]\n",
      "loss: 0.177647  [ 6464/60000]\n",
      "loss: 0.021379  [12864/60000]\n",
      "loss: 0.113740  [19264/60000]\n",
      "loss: 0.140611  [25664/60000]\n",
      "loss: 0.100451  [32064/60000]\n",
      "loss: 0.035238  [38464/60000]\n",
      "loss: 0.144747  [44864/60000]\n",
      "loss: 0.118703  [51264/60000]\n",
      "loss: 0.080213  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.279972 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.147859  [   64/60000]\n",
      "loss: 0.124290  [ 6464/60000]\n",
      "loss: 0.057370  [12864/60000]\n",
      "loss: 0.118538  [19264/60000]\n",
      "loss: 0.238156  [25664/60000]\n",
      "loss: 0.234030  [32064/60000]\n",
      "loss: 0.154020  [38464/60000]\n",
      "loss: 0.148830  [44864/60000]\n",
      "loss: 0.086750  [51264/60000]\n",
      "loss: 0.081456  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.285276 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.053286  [   64/60000]\n",
      "loss: 0.180215  [ 6464/60000]\n",
      "loss: 0.044878  [12864/60000]\n",
      "loss: 0.103455  [19264/60000]\n",
      "loss: 0.055405  [25664/60000]\n",
      "loss: 0.165660  [32064/60000]\n",
      "loss: 0.082690  [38464/60000]\n",
      "loss: 0.111582  [44864/60000]\n",
      "loss: 0.125815  [51264/60000]\n",
      "loss: 0.221847  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.270498 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.174171  [   64/60000]\n",
      "loss: 0.102924  [ 6464/60000]\n",
      "loss: 0.081783  [12864/60000]\n",
      "loss: 0.249301  [19264/60000]\n",
      "loss: 0.067124  [25664/60000]\n",
      "loss: 0.209272  [32064/60000]\n",
      "loss: 0.098340  [38464/60000]\n",
      "loss: 0.077038  [44864/60000]\n",
      "loss: 0.063131  [51264/60000]\n",
      "loss: 0.070634  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.276211 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.102647  [   64/60000]\n",
      "loss: 0.103794  [ 6464/60000]\n",
      "loss: 0.048141  [12864/60000]\n",
      "loss: 0.053695  [19264/60000]\n",
      "loss: 0.039713  [25664/60000]\n",
      "loss: 0.187762  [32064/60000]\n",
      "loss: 0.052313  [38464/60000]\n",
      "loss: 0.142336  [44864/60000]\n",
      "loss: 0.099952  [51264/60000]\n",
      "loss: 0.047326  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.277840 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.315352  [   64/60000]\n",
      "loss: 0.161844  [ 6464/60000]\n",
      "loss: 0.083849  [12864/60000]\n",
      "loss: 0.043999  [19264/60000]\n",
      "loss: 0.196003  [25664/60000]\n",
      "loss: 0.252324  [32064/60000]\n",
      "loss: 0.105943  [38464/60000]\n",
      "loss: 0.304402  [44864/60000]\n",
      "loss: 0.092989  [51264/60000]\n",
      "loss: 0.132309  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.273648 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.080121  [   64/60000]\n",
      "loss: 0.021933  [ 6464/60000]\n",
      "loss: 0.068141  [12864/60000]\n",
      "loss: 0.308582  [19264/60000]\n",
      "loss: 0.148048  [25664/60000]\n",
      "loss: 0.101726  [32064/60000]\n",
      "loss: 0.124618  [38464/60000]\n",
      "loss: 0.095124  [44864/60000]\n",
      "loss: 0.264030  [51264/60000]\n",
      "loss: 0.101104  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.294281 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.108048  [   64/60000]\n",
      "loss: 0.168106  [ 6464/60000]\n",
      "loss: 0.040558  [12864/60000]\n",
      "loss: 0.163452  [19264/60000]\n",
      "loss: 0.066282  [25664/60000]\n",
      "loss: 0.178275  [32064/60000]\n",
      "loss: 0.232396  [38464/60000]\n",
      "loss: 0.171440  [44864/60000]\n",
      "loss: 0.279094  [51264/60000]\n",
      "loss: 0.141714  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.285127 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.065070  [   64/60000]\n",
      "loss: 0.100274  [ 6464/60000]\n",
      "loss: 0.105433  [12864/60000]\n",
      "loss: 0.038496  [19264/60000]\n",
      "loss: 0.063518  [25664/60000]\n",
      "loss: 0.089714  [32064/60000]\n",
      "loss: 0.083210  [38464/60000]\n",
      "loss: 0.187690  [44864/60000]\n",
      "loss: 0.131753  [51264/60000]\n",
      "loss: 0.049056  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.285927 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
